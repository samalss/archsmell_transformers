{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198,
     "referenced_widgets": [
      "47046745fdef4cefbbbebaae50fd3c6d",
      "98d97588a4c04aff94ad767b59788e70",
      "2c6afbae9d554fef9b8a172d60286496",
      "380e74ce17e34a7e902283b18ad1c2c7",
      "beda0a3c6a7c4d5f849996a6892b4f2e",
      "71edacacd6854f14b593711b30d764fb",
      "89050a50900b492e8ad435ba0d7cbb56",
      "aeb36a292b8b408380b5e55ec9a60465",
      "e866400302f44f0498937f9ee65edcb3",
      "0760dd454419484d9c8103911df39b67",
      "e2719aceaa53425497d2da1aeb0552a8",
      "6fcbec321791497dad0a2ca048c3915a",
      "07d2af16099a414c98c939267afdf9f4",
      "f8e840607a8d4a92a9838616f352bdf4",
      "e310fc7e705f43149832e65eb384e6fc",
      "b4b08f0c64cd44da9b357d9e0d86298d",
      "287bbb59fb9a4f148f6c1dbee6826cdf",
      "561fdf71fd1b48b296f3546515c825c1",
      "b2a64b5f57d1481fbea6f2962a7339fa",
      "4323eaf91f7c417999c1ddb617b0157e",
      "d676d21afec34196b07ed9d7bd7f6151",
      "14cf8b8042864bf5af726d482d70ae09",
      "42c8aa43101f46dca1850e989216cbb7",
      "9c15143940e145bfa1fb986b3d75f902",
      "6d8b7077a24b4d9c8d27b1beb23cc3fb",
      "d306ecd3e5a149b79bcbb11b8b1eeab7",
      "c78e90e3b6924815847526d71cb7d5d4",
      "708f10aaf8a2452a91b7ad6992515e70",
      "e222dced55844f02a1b02a54faf6f051",
      "9d3b356a9a6d4e1399e9d2dbbdc488f2",
      "2c9702387f0542e9a9cee826f7b2ce3e",
      "869de1e8bf70494485a966035251b8a6",
      "ccf3ad27d4c14f31a77a11139554da3f"
     ]
    },
    "id": "yfEgyce4ZGTV",
    "outputId": "626a3fac-c934-48a5-8358-df087b8bf414"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OeKU9SWVZr1Y"
   },
   "outputs": [],
   "source": [
    "# --- 1. Loading and preprocessing ---\n",
    "def preprocess_code(code: str) -> str:\n",
    "    code = re.sub(r'//.*?\\n', '', code)\n",
    "    code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.S)\n",
    "    return ' '.join(code.split())\n",
    "\n",
    "data_df = pd.read_csv('dataset.tsv', sep='\\t')\n",
    "data_df = data_df[~data_df[\"refactoring_type\"].isin([\"no_refactoring\", \"Extract Variable\", \"Move Method\"])]\n",
    "data_df['code'] = data_df['code'].apply(preprocess_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Labels ---\n",
    "unique_labels = sorted(data_df['refactoring_type'].unique())\n",
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Data split ---\n",
    "train_df, temp_df = train_test_split(data_df, test_size=0.2, random_state=42, stratify=data_df[\"refactoring_type\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"refactoring_type\"])\n",
    "\n",
    "print(\"Train:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Tokenizer & Model ---\n",
    "model_name = \"Salesforce/codet5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "task_prefix = \"refactoring classification: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Tokenization function ---\n",
    "def tokenize_batch(batch):\n",
    "    inputs = [task_prefix + code for code in batch[\"code\"]]\n",
    "\n",
    "    model_inputs = tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(batch[\"refactoring_type\"], padding=\"max_length\", truncation=True, max_length=10)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"] \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Dataset prep ---\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df).map(\n",
    "    tokenize_batch, batched=True, remove_columns=[\"code\", \"refactoring_type\"]\n",
    ")\n",
    "\n",
    "val_dataset = Dataset.from_pandas(val_df).map(\n",
    "    tokenize_batch, batched=True, remove_columns=[\"code\", \"refactoring_type\"]\n",
    ")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_df).map(\n",
    "    tokenize_batch, batched=True, remove_columns=[\"code\", \"refactoring_type\"]\n",
    ")\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "print(train_dataset[0][\"labels\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Metrics (based on decoded strings)---\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.strip() for label in decoded_labels]\n",
    "\n",
    "    acc = accuracy_score(decoded_labels, decoded_preds)\n",
    "    f1 = f1_score(decoded_labels, decoded_preds, average=\"macro\", zero_division=1)\n",
    "    precision = precision_score(decoded_labels, decoded_preds, average=\"macro\", zero_division=1)\n",
    "    recall = recall_score(decoded_labels, decoded_preds, average=\"macro\", zero_division=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "mPVhr08PZhR4",
    "outputId": "ffb1e510-ec38-42d4-fdf4-8a4627654896"
   },
   "outputs": [],
   "source": [
    "# --- 8. Training Arguments ---\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"codet5_refactoring_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=True,\n",
    "    logging_steps=100,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Trainer ---\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. Training ---\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8GK77uzg2Yk"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "true_labels = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    input_ids = batch[\"input_ids\"].to(model.device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(model.device)\n",
    "    labels = batch[\"labels\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=10)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    preds.extend([pred.strip() for pred in decoded_preds])\n",
    "    true_labels.extend([label.strip() for label in decoded_labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUZ-kn6MrNlc",
    "outputId": "394dad57-ac34-4b3a-a4c5-088978e554bb"
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "print(f\"\\nðŸ“Š Test Set Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy_score(true_labels, preds):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(true_labels, preds, average='macro'):.4f}\")\n",
    "print(f\"Precision: {precision_score(true_labels, preds, average='macro', zero_division=1):.4f}\")\n",
    "print(f\"Recall:    {recall_score(true_labels, preds, average='macro', zero_division=1):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ck8XirLedMl0",
    "outputId": "6a74911e-3c1c-4eb8-dfd1-0583977129e8"
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_labels, preds, labels=unique_labels)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=unique_labels, yticklabels=unique_labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
